{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc89544f",
   "metadata": {},
   "source": [
    "# Cleaning Student Names\n",
    "D.M. Burt, June 26 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19d58ac",
   "metadata": {},
   "source": [
    "### 4.5.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "567ea9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14d115f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student ID</th>\n",
       "      <th>student_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>grade</th>\n",
       "      <th>school_name</th>\n",
       "      <th>reading_score</th>\n",
       "      <th>math_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Paul Bradley</td>\n",
       "      <td>M</td>\n",
       "      <td>9th</td>\n",
       "      <td>Huang High School</td>\n",
       "      <td>66</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Victor Smith</td>\n",
       "      <td>M</td>\n",
       "      <td>12th</td>\n",
       "      <td>Huang High School</td>\n",
       "      <td>94</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Kevin Rodriguez</td>\n",
       "      <td>M</td>\n",
       "      <td>12th</td>\n",
       "      <td>Huang High School</td>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Dr. Richard Scott</td>\n",
       "      <td>M</td>\n",
       "      <td>12th</td>\n",
       "      <td>Huang High School</td>\n",
       "      <td>67</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Bonnie Ray</td>\n",
       "      <td>F</td>\n",
       "      <td>9th</td>\n",
       "      <td>Huang High School</td>\n",
       "      <td>97</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Student ID       student_name gender grade        school_name  \\\n",
       "0           0       Paul Bradley      M   9th  Huang High School   \n",
       "1           1       Victor Smith      M  12th  Huang High School   \n",
       "2           2    Kevin Rodriguez      M  12th  Huang High School   \n",
       "3           3  Dr. Richard Scott      M  12th  Huang High School   \n",
       "4           4         Bonnie Ray      F   9th  Huang High School   \n",
       "\n",
       "   reading_score  math_score  \n",
       "0             66          79  \n",
       "1             94          61  \n",
       "2             90          60  \n",
       "3             67          58  \n",
       "4             97          84  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_data_df = pd.read_csv('./Resources/students_complete.csv')\n",
    "\n",
    "student_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90c90958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Paul Bradley',\n",
       " 'Victor Smith',\n",
       " 'Kevin Rodriguez',\n",
       " 'Dr. Richard Scott',\n",
       " 'Bonnie Ray',\n",
       " 'Bryan Miranda',\n",
       " 'Sheena Carter',\n",
       " 'Nicole Baker',\n",
       " 'Michael Roth',\n",
       " 'Matthew Greene']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put the student names in a list.\n",
    "student_names = student_data_df[\"student_name\"].tolist()\n",
    "\n",
    "student_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "effc6edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Paul', 'Bradley'] 2\n",
      "['Victor', 'Smith'] 2\n",
      "['Kevin', 'Rodriguez'] 2\n",
      "['Dr.', 'Richard', 'Scott'] 3\n",
      "['Bonnie', 'Ray'] 2\n",
      "['Bryan', 'Miranda'] 2\n",
      "['Sheena', 'Carter'] 2\n",
      "['Nicole', 'Baker'] 2\n",
      "['Michael', 'Roth'] 2\n",
      "['Matthew', 'Greene'] 2\n"
     ]
    }
   ],
   "source": [
    "# Split the student name and determine the length of the split name.\n",
    "for name in student_names[:10]:\n",
    "    print(name.split(), len(name.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55fa70b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1531"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new list and use it for the for loop to iterate through the list.\n",
    "students_to_fix = []\n",
    "\n",
    "# Use an if statement to check the length of the name.\n",
    "# If the name is greater than or equal to \"3\", add the name to the list.\n",
    "\n",
    "for name in student_names:\n",
    "    if len(name.split()) >= 3:\n",
    "        students_to_fix.append(name)\n",
    "\n",
    "# Get the length of the students whose names are greater than or equal to \"3\".\n",
    "len(students_to_fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84d93c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dr. Richard Scott',\n",
       " 'Dr. Jordan Carson',\n",
       " 'Madeline Snyder MD',\n",
       " 'Mr. Dylan Taylor MD',\n",
       " 'Dr. Scott Gill',\n",
       " 'Miss Madison Everett',\n",
       " 'Virginia Ramirez MD',\n",
       " 'Joseph Morales III',\n",
       " 'Angela Perkins DVM',\n",
       " 'Heather Allen MD']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students_to_fix[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7889b445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dr.', 'Dr.', 'Mr.', 'Dr.', 'Miss', 'Luke', 'Dr.', 'Mrs.', 'Mrs.', 'Mr.', 'Dr.', 'Mr.', 'Mr.', 'Mary', 'Mrs.', 'Mrs.', 'Mr.', 'Tara', 'Dr.', 'Mr.', 'Mrs.', 'Mr.', 'Mr.', 'John', 'Mr.', 'Mrs.', 'Mr.', 'Dr.', 'Mr.', 'Mr.', 'Dale', 'Dr.', 'Dr.', 'Dr.', 'Ms.', 'Dr.', 'Dr.', 'Mr.', 'Mrs.', 'Amy', 'Mr.', 'Dr.', 'Mr.', 'Mr.', 'Mrs.', 'Mrs.', 'Mr.', 'Lisa', 'Mr.', 'Dr.', 'Mr.', 'Mr.', 'Mr.', 'Dr.', 'Mr.', 'Mark', 'Mrs.', 'Dr.', 'Dr.', 'Miss', 'Mr.', 'Miss', 'Mr.', 'Mrs.', 'Mr.', 'Mrs.', 'Mr.', 'Mr.', 'Mr.', 'Dr.', 'Dr.', 'Miss', 'Mr.', 'Mrs.', 'Mr.', 'Tara', 'Dr.', 'Mr.', 'Cody', 'Mr.', 'Dr.', 'Mr.', 'Ms.', 'Dr.', 'Mr.', 'Mrs.', 'Sara', 'Mr.', 'Mrs.', 'Dr.', 'Mr.', 'Dr.', 'Mr.', 'Mrs.', 'Mr.', 'Mr.', 'Mr.', 'Mr.', 'Mr.', 'Dr.', 'Mrs.', 'Mr.', 'Mrs.', 'Dr.', 'Ryan', 'Mrs.', 'Mr.', 'Ms.', 'Mr.', 'Dr.', 'John', 'Mr.', 'Dr.', 'Dr.', 'Mrs.', 'Dr.', 'Mrs.', 'Mr.', 'Mr.', 'Mrs.', 'Dr.', 'Dr.', 'Miss', 'Miss', 'Mr.', 'Mr.', 'Mr.', 'Dr.', 'Dr.', 'Mrs.', 'Mr.', 'Ms.', 'Mr.', 'Miss', 'Tony', 'Dr.', 'Mr.', 'Mr.', 'Mrs.', 'Mr.', 'Mrs.', 'Miss', 'Mrs.', 'Jodi', 'Mr.', 'Mr.', 'Mrs.', 'Mr.', 'Mr.', 'Mrs.', 'Mrs.', 'Mrs.', 'Mr.', 'Mr.', 'Mr.', 'Mrs.', 'Dr.', 'Mr.', 'Mr.', 'Mrs.', 'Mr.', 'Mrs.', 'Mr.', 'Dr.', 'Mr.', 'Mr.', 'Ruth', 'Dr.', 'Mr.', 'Ms.', 'Dr.', 'Mr.', 'Mrs.', 'Mr.', 'Dr.', 'Dr.', 'John', 'Dr.', 'Mr.', 'Mrs.', 'Mrs.', 'Mrs.', 'Dr.', 'Mrs.', 'John', 'Amy', 'Adam', 'Dr.', 'Eric', 'Mrs.', 'Mr.', 'Mrs.', 'Dr.', 'Dr.', 'Kyle', 'Mr.', 'Ms.', 'Lynn', 'Dr.', 'Mr.', 'Jon', 'Mrs.', 'Mrs.', 'Mrs.', 'Dr.', 'Mrs.', 'Dr.', 'Dr.', 'Dr.', 'Mrs.', 'Mrs.', 'Judy', 'Mr.', 'Dr.', 'Mr.', 'Mrs.', 'Dr.', 'Mr.', 'Mr.', 'Mr.', 'Sara', 'Dr.', 'Dr.', 'Mrs.', 'Tara', 'Dr.', 'Mrs.', 'Dr.', 'Miss', 'Mrs.', 'Mr.', 'Dr.', 'Miss', 'Tina', 'Dr.', 'Eric', 'Ms.', 'Ms.', 'Mr.', 'Mrs.', 'Dr.', 'Dr.', 'Mr.', 'Mr.', 'Dr.', 'Mr.', 'Mr.', 'Dr.', 'Miss', 'Dr.', 'Paul', 'Mrs.', 'Mr.', 'Mrs.', 'Mr.', 'Mr.', 'Mr.', 'Dr.', 'Mrs.', 'Dr.', 'Dr.', 'Mrs.', 'Mrs.', 'Dr.', 'Dr.', 'Dr.', 'Mr.', 'Ms.', 'Dr.', 'Mr.', 'Mrs.', 'Dr.', 'Mrs.', 'Dr.', 'Mrs.', 'Mr.', 'Dr.', 'Mrs.', 'Mrs.', 'Mrs.', 'Dr.', 'Dr.', 'Mr.', 'Mr.', 'Mr.', 'Dr.', 'Marc', 'Mr.', 'Dr.', 'Dr.', 'Dr.', 'Mrs.', 'Dr.', 'Mrs.', 'Mrs.', 'Mr.', 'Mrs.', 'Dr.', 'Dr.', 'Dr.', 'Dr.', 'Mr.', 'Dr.', 'Mr.', 'Mrs.', 'Dr.', 'Dr.', 'Dr.', 'Amy', 'Dr.', 'Mr.', 'Mrs.', 'Mr.', 'Mrs.', 'Dr.', 'Dr.', 'Mr.', 'Mrs.', 'Dr.', 'Jill', 'Mary', 'Carl', 'Mr.', 'Dr.', 'Jose', 'Mrs.', 'Mary', 'Ms.', 'Jose', 'Lisa', 'Mrs.', 'Mr.', 'Miss', 'Mr.', 'Eric', 'Mr.', 'Mrs.', 'Mrs.', 'Miss', 'Emma', 'Mrs.', 'Dr.', 'Mrs.', 'Mr.', 'Dr.', 'Mr.', 'Mr.', 'Dr.', 'Dr.', 'Mrs.', 'Dr.', 'Dr.', 'Mr.', 'Mr.', 'Ms.', 'Mr.', 'Gary', 'Mr.', 'Lori', 'Mrs.', 'Mr.', 'Mr.', 'Mrs.', 'Mrs.', 'Noah', 'Dawn', 'Dr.', 'Mr.', 'Mr.', 'Mrs.', 'Mrs.', 'Mrs.', 'Dr.', 'Chad', 'Mr.', 'Paul', 'Mrs.', 'Dr.', 'Mrs.', 'Mrs.', 'Mrs.', 'Dr.', 'Dr.', 'Mrs.', 'Mrs.', 'Dr.', 'Miss', 'Mrs.', 'Eric', 'Dr.', 'Mrs.', 'Dr.', 'Mr.', 'Dr.', 'Adam', 'Mr.', 'Dr.', 'Dr.', 'Mr.', 'Mr.', 'Mr.', 'Mr.', 'Anne', 'Mr.', 'Mrs.', 'Troy', 'Mr.', 'Mrs.', 'Dr.', 'Mr.', 'Mr.', 'Mr.', 'Mr.', 'Miss', 'Mr.', 'Anna', 'John', 'Mr.', 'Mr.', 'Mrs.', 'Eric', 'Mr.', 'Dr.', 'Dr.', 'Mr.', 'Mr.', 'Ryan', 'Mrs.', 'Dr.', 'Emma', 'Mr.', 'Mr.', 'Mrs.', 'Miss', 'Mr.', 'Mr.', 'Mrs.', 'Mrs.', 'Mr.', 'Mr.', 'Mr.', 'Mrs.', 'Mr.', 'Dr.', 'Lisa', 'Mr.', 'Dr.', 'Mrs.', 'John', 'Mrs.', 'Ms.', 'Mrs.', 'Mrs.', 'Dr.', 'Mr.', 'Mrs.', 'Mr.', 'Amy', 'Dr.', 'Mr.', 'Dr.', 'Mrs.', 'Dr.', 'Dr.', 'Lori', 'Mr.', 'Dr.', 'Mrs.', 'Amy', 'Dr.', 'Mrs.', 'Dr.', 'Anne', 'Dr.', 'Mr.', 'Mr.', 'Mr.', 'Mr.', 'Mr.', 'Mrs.', 'Mike', 'Mrs.', 'Todd', 'Mrs.', 'Mr.', 'Mr.', 'Mrs.', 'Dr.', 'Mr.', 'Mrs.', 'Dr.', 'Dr.', 'Mrs.', 'Mrs.', 'Mr.', 'Dr.', 'Mrs.', 'Mrs.', 'Dr.', 'Dr.', 'Miss', 'Mr.', 'Mrs.', 'Dr.', 'Dr.', 'Mrs.', 'Mr.', 'Mrs.', 'Mr.', 'Mr.', 'Dr.', 'Mr.', 'Dr.', 'Mrs.', 'Dr.', 'Ms.', 'Mr.', 'Miss', 'Dr.', 'Miss', 'Dr.', 'Leah', 'Miss', 'Mr.', 'Mr.', 'Dr.', 'Mr.', 'Dr.', 'Dr.', 'Dr.', 'Mr.', 'Dr.', 'Dr.', 'Dr.', 'Mr.', 'Dr.', 'Ian', 'Dr.', 'Mr.', 'Dr.', 'Mr.', 'Dr.', 'Mrs.', 'Miss', 'Dr.', 'Mrs.', 'Ms.', 'Dr.', 'Dr.', 'Mark', 'Mr.', 'Kari', 'Mrs.', 'Mrs.', 'Mr.', 'Mrs.', 'Dr.', 'Dr.', 'Mrs.', 'Dr.', 'Mrs.', 'Kara', 'Mark', 'John', 'Mrs.', 'Dr.', 'Mrs.', 'Mr.', 'Eric', 'John', 'Dr.', 'Mrs.', 'Dr.', 'Mr.', 'Paul', 'Dr.', 'Mrs.', 'Dr.', 'Dr.', 'Dr.', 'Adam', 'Mrs.', 'Ms.', 'Dr.', 'Mrs.', 'Dr.', 'Ms.', 'Mrs.', 'Mr.', 'Mr.', 'Mrs.', 'Dr.', 'Mrs.', 'Mr.', 'Dr.', 'Mr.', 'Dr.', 'Dr.', 'Paul', 'Mrs.', 'Cory', 'Mrs.', 'Dr.', 'Dr.', 'Dr.', 'Mr.', 'Mr.', 'Erin', 'Dr.', 'Dr.', 'Ms.', 'Mrs.', 'Mr.', 'Miss', 'Mr.', 'Mr.', 'Mr.', 'Ms.', 'Mrs.', 'Mr.', 'Mrs.', 'Miss', 'Ms.', 'Dr.', 'Dr.', 'Mrs.', 'Mr.', 'Mrs.', 'John', 'Lisa', 'Mr.', 'Mr.', 'Mrs.', 'Mr.', 'Jon', 'Mrs.', 'Dr.', 'Greg', 'Ms.', 'Mrs.', 'Mr.', 'Mrs.', 'Miss', 'Mr.', 'Dr.', 'Joe', 'Dr.', 'Mark', 'Dr.', 'Mrs.', 'Miss', 'Mr.', 'Mr.', 'Mr.', 'Mrs.', 'Dr.', 'Mr.', 'Mr.', 'Mr.', 'Adam', 'Mr.', 'Mr.', 'Dana', 'Dr.', 'Mr.', 'Dr.', 'Mrs.', 'Mr.', 'Erik', 'Mrs.', 'Dr.', 'Miss', 'Mrs.', 'Ms.', 'Mr.', 'Mr.', 'Mr.', 'John', 'Gail', 'Todd', 'Mr.', 'Mr.', 'Mrs.', 'Ms.', 'Ryan', 'Mrs.', 'Mrs.', 'Dr.', 'Erik', 'Omar', 'Mr.', 'Dr.', 'Cody', 'Ms.', 'Dr.', 'Mrs.', 'Dr.', 'Mr.', 'Mr.', 'Miss', 'Mark', 'Dr.', 'Dr.', 'Mr.', 'Mrs.', 'Mr.', 'Mr.', 'Mr.', 'Mrs.', 'Mr.', 'Mrs.', 'Mr.', 'Dr.', 'Dr.', 'Mr.', 'Mr.', 'Mr.', 'Dr.', 'Miss', 'Mrs.', 'Seth', 'Dr.', 'Mrs.', 'Ryan', 'Mrs.', 'Mrs.', 'Mrs.', 'Mr.', 'Mrs.', 'Dr.', 'Mr.', 'Mrs.', 'Ryan', 'Mrs.', 'Mr.', 'Dr.', 'Dr.', 'Mr.', 'Dr.', 'Dr.', 'Mrs.', 'Ms.', 'Dr.', 'Dr.', 'Mr.', 'Mr.', 'Ms.', 'Dr.', 'Dr.', 'Dr.', 'Mr.', 'Mrs.', 'Mr.', 'Lisa', 'Mr.', 'Dr.', 'Chad', 'Gina', 'Dr.', 'Mr.', 'Mr.', 'Mrs.', 'Amy', 'Mr.', 'Mrs.', 'Mr.', 'Dr.', 'Mr.', 'Dr.', 'Mrs.', 'Lisa', 'Mrs.', 'Dr.', 'Miss', 'Mr.', 'Mr.', 'Ms.', 'Mrs.', 'Mr.', 'Mrs.', 'Mr.', 'Dr.', 'Dr.', 'Mr.', 'Lisa', 'Dr.', 'Mr.', 'Ms.', 'Mrs.', 'Mr.', 'Dr.', 'Dr.', 'Mrs.', 'Sean', 'Dr.', 'Dr.', 'Mr.', 'Mr.', 'Miss', 'Miss', 'Dr.', 'Mr.', 'Dr.', 'Dr.', 'Mrs.', 'Mr.', 'Mrs.', 'Mrs.', 'Dr.', 'Mrs.', 'Dr.', 'Mr.', 'Mrs.', 'Mr.', 'Mr.', 'Todd', 'Dr.', 'Mrs.', 'Mrs.', 'Miss', 'Dr.', 'Mrs.', 'Mr.', 'Mr.', 'Mrs.', 'Adam', 'Mrs.', 'Ms.', 'Tony', 'Dr.', 'Miss', 'Toni', 'Ms.', 'Mr.', 'Mr.', 'Dr.', 'Ms.', 'Dr.', 'Mrs.', 'Dr.', 'Dr.', 'Dr.', 'Jose', 'Dr.', 'Dr.', 'Amy', 'John', 'Mrs.', 'Mr.', 'Mrs.', 'Mrs.', 'Miss', 'Mr.', 'Dr.', 'Mary', 'Mark', 'Dr.', 'Ms.', 'Ms.', 'Dr.', 'Mr.', 'Dr.', 'Miss', 'Mr.', 'Dr.', 'Troy', 'John', 'Dr.', 'Kim', 'Mr.', 'Mr.', 'Miss', 'Mary', 'Mrs.', 'Mrs.', 'Mrs.', 'Mr.', 'Dr.', 'Ms.', 'Mrs.', 'Anna', 'Mr.', 'Mrs.', 'Mr.', 'Mr.', 'Dr.', 'Mrs.', 'Dr.', 'Dr.']\n"
     ]
    }
   ],
   "source": [
    "# Add the prefixes less than or equal to 4 to a new list.\n",
    "prefixes = []\n",
    "for name in students_to_fix:\n",
    "    if len(name.split()[0]) <= 4:\n",
    "        prefixes.append(name.split()[0])\n",
    "\n",
    "print(prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6431d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MD', 'MD', 'MD', 'III', 'DVM', 'MD', 'MD', 'MD', 'DDS', 'DVM', 'II', 'MD', 'MD', 'DDS', 'MD', 'DDS', 'MD', 'MD', 'PhD', 'MD', 'DVM', 'Lee', 'MD', 'DDS', 'MD', 'MD', 'MD', 'MD', 'MD', 'MD', 'DDS', 'Jr.', 'DVM', 'MD', 'MD', 'PhD', 'IV', 'MD', 'DDS', 'DDS', 'DDS', 'MD', 'DDS', 'MD', 'DVM', 'IV', 'MD', 'DDS', 'MD', 'MD', 'DVM', 'Jr.', 'MD', 'PhD', 'II', 'MD', 'DDS', 'DDS', 'DDS', 'Jr.', 'III', 'MD', 'MD', 'MD', 'DDS', 'Jr.', 'DDS', 'DVM', 'DDS', 'DVM', 'MD', 'DDS', 'PhD', 'DDS', 'DDS', 'Jr.', 'Jr.', 'DVM', 'DDS', 'MD', 'MD', 'DVM', 'DDS', 'DVM', 'Jr.', 'MD', 'Jr.', 'MD', 'PhD', 'PhD', 'DDS', 'MD', 'DDS', 'DVM', 'Cox', 'DVM', 'MD', 'Jr.', 'MD', 'DDS', 'MD', 'MD', 'DDS', 'DDS', 'Roy', 'DDS', 'DDS', 'DDS', 'II', 'PhD', 'MD', 'PhD', 'DDS', 'MD', 'DDS', 'Jr.', 'Day', 'DDS', 'MD', 'PhD', 'DDS', 'Jr.', 'DDS', 'MD', 'MD', 'MD', 'MD', 'DDS', 'MD', 'DDS', 'PhD', 'DVM', 'DDS', 'MD', 'MD', 'MD', 'DDS', 'Jr.', 'Jr.', 'DDS', 'Jr.', 'MD', 'MD', 'PhD', 'PhD', 'DDS', 'MD', 'MD', 'III', 'DVM', 'PhD', 'Jr.', 'II', 'DDS', 'DDS', 'DVM', 'MD', 'II', 'MD', 'DDS', 'MD', 'DDS', 'PhD', 'DDS', 'DDS', 'II', 'DVM', 'DDS', 'Jr.', 'DVM', 'MD', 'MD', 'DVM', 'MD', 'DDS', 'DVM', 'DDS', 'MD', 'II', 'PhD', 'MD', 'MD', 'MD', 'DDS', 'MD', 'MD', 'DDS', 'DDS', 'MD', 'DDS', 'PhD', 'DVM', 'DVM', 'MD', 'MD', 'DDS', 'DDS', 'PhD', 'MD', 'IV', 'DDS', 'Jr.', 'DDS', 'Jr.', 'MD', 'MD', 'MD', 'DDS', 'MD', 'DVM', 'DVM', 'DDS', 'DDS', 'Jr.', 'MD', 'MD', 'DDS', 'DDS', 'MD', 'MD', 'MD', 'MD', 'DVM', 'MD', 'DVM', 'DVM', 'MD', 'DDS', 'MD', 'Jr.', 'DDS', 'MD', 'MD', 'DVM', 'Jr.', 'DDS', 'MD', 'MD', 'PhD', 'DDS', 'Jr.', 'MD', 'DDS', 'MD', 'DDS', 'Jr.', 'Jr.', 'DVM', 'MD', 'DDS', 'PhD', 'MD', 'PhD', 'MD', 'V', 'II', 'MD', 'PhD', 'DVM', 'MD', 'MD', 'PhD', 'MD', 'MD', 'MD', 'DDS', 'DVM', 'Jr.', 'MD', 'Jr.', 'Jr.', 'DDS', 'PhD', 'DVM', 'DVM', 'MD', 'MD', 'MD', 'DVM', 'MD', 'DDS', 'MD', 'DDS', 'Jr.', 'MD', 'DDS', 'DDS', 'Jr.', 'DVM', 'DVM', 'DDS', 'MD', 'MD', 'DVM', 'MD', 'MD', 'MD', 'DDS', 'MD', 'Jr.', 'MD', 'MD', 'PhD', 'PhD', 'DDS', 'DDS', 'DDS', 'MD', 'MD', 'PhD', 'Jr.', 'MD', 'DDS', 'III', 'DVM', 'Jr.', 'DDS', 'DDS', 'MD', 'DVM', 'MD', 'DDS', 'MD', 'PhD', 'DDS', 'Lee', 'MD', 'Jr.', 'MD', 'DVM', 'DDS', 'DDS', 'MD', 'MD', 'DVM', 'DVM', 'DVM', 'MD', 'DDS', 'DVM', 'DDS', 'MD', 'MD', 'MD', 'DDS', 'PhD', 'DDS', 'DVM', 'DDS', 'DVM', 'DDS', 'DVM', 'DVM', 'DDS', 'II', 'MD', 'III', 'DDS', 'DDS', 'DVM', 'DVM', 'MD', 'Jr.', 'II', 'MD', 'PhD', 'PhD', 'MD', 'DDS', 'DVM', 'DVM', 'MD', 'MD', 'DVM', 'DVM', 'PhD', 'Jr.', 'Jr.', 'MD', 'MD', 'DDS', 'DDS', 'III', 'PhD', 'Jr.', 'MD', 'MD', 'MD', 'DDS', 'MD', 'DDS', 'MD', 'DVM', 'PhD', 'MD', 'MD', 'PhD', 'Jr.', 'MD', 'MD', 'MD', 'MD', 'MD', 'MD', 'DVM', 'DVM', 'PhD', 'DDS', 'DDS', 'MD', 'DDS', 'MD', 'DVM', 'DVM', 'DDS', 'DVM', 'DDS', 'MD', 'MD', 'DVM', 'DVM', 'DDS', 'Jr.', 'PhD', 'MD', 'DVM', 'DVM', 'DDS', 'DVM', 'MD', 'MD', 'MD', 'II', 'DDS', 'DDS', 'DDS', 'MD', 'Jr.', 'MD', 'Jr.', 'DDS', 'MD', 'MD', 'DVM', 'MD', 'DDS', 'DDS', 'PhD', 'Jr.', 'Jr.', 'Jr.', 'DDS', 'Jr.', 'MD', 'MD', 'DDS', 'MD', 'Jr.', 'MD', 'DDS', 'Jr.', 'DDS', 'MD', 'MD', 'Jr.', 'PhD', 'DDS', 'MD', 'II', 'PhD', 'DVM', 'MD', 'DDS', 'PhD', 'MD', 'MD', 'DDS', 'Jr.', 'MD', 'DVM', 'MD', 'MD', 'MD', 'MD', 'MD', 'DDS', 'DVM', 'PhD', 'DVM', 'III', 'Jr.', 'DVM', 'MD', 'MD', 'V', 'Jr.', 'MD', 'DVM', 'MD', 'DDS', 'DVM', 'DDS', 'Jr.', 'MD', 'PhD', 'DVM', 'DDS', 'PhD', 'MD', 'DDS', 'DDS', 'MD', 'DVM', 'IV', 'Jr.', 'MD', 'MD', 'Jr.', 'PhD', 'II', 'Jr.', 'MD', 'MD', 'MD', 'Jr.', 'MD', 'DVM', 'PhD', 'PhD', 'DDS', 'DDS', 'PhD', 'MD', 'Jr.', 'MD', 'DDS', 'MD', 'DDS', 'DVM', 'DDS', 'DVM', 'MD', 'MD', 'PhD', 'Jr.', 'Jr.', 'MD', 'DDS', 'MD', 'DVM', 'MD', 'DVM', 'DDS', 'PhD', 'PhD', 'Kim', 'DDS', 'PhD', 'DVM', 'PhD', 'DVM', 'DDS', 'MD', 'Jr.', 'PhD', 'MD', 'MD', 'II', 'III', 'MD', 'DDS', 'DDS', 'PhD', 'MD', 'DVM', 'MD', 'DDS', 'MD', 'DDS', 'Jr.', 'DDS', 'DDS', 'MD', 'IV', 'Jr.', 'DDS', 'DDS', 'Jr.', 'DVM', 'DVM', 'DVM', 'DVM', 'MD', 'DVM', 'DDS', 'MD', 'MD', 'DDS', 'DDS', 'DVM', 'III', 'DVM', 'MD', 'DVM', 'DDS', 'MD', 'MD', 'DVM', 'DVM', 'MD', 'III', 'DDS', 'MD', 'DDS', 'DVM', 'Jr.', 'III', 'MD', 'MD', 'PhD', 'DVM', 'DDS', 'MD', 'Jr.', 'DDS', 'MD', 'II', 'MD', 'Jr.', 'DDS', 'PhD', 'DDS', 'DDS', 'II', 'Jr.', 'DDS', 'MD', 'II', 'MD', 'MD', 'MD', 'Jr.', 'DDS', 'MD', 'DVM', 'PhD', 'MD', 'DVM', 'DDS', 'DDS', 'DVM', 'DDS', 'DDS', 'MD', 'MD', 'MD', 'MD', 'DDS', 'DVM', 'PhD', 'DDS', 'DDS', 'MD', 'MD', 'MD', 'DDS', 'DVM', 'MD', 'II', 'MD', 'Jr.', 'Jr.', 'MD', 'MD', 'MD', 'MD', 'DVM', 'MD', 'Jr.', 'PhD', 'PhD', 'PhD', 'DDS', 'Jr.', 'DVM', 'DDS', 'MD', 'DVM', 'PhD', 'MD', 'Jr.', 'Jr.', 'DVM', 'MD', 'DDS', 'MD', 'MD', 'Lee', 'MD', 'MD', 'MD', 'DDS', 'PhD', 'MD', 'PhD', 'MD', 'DVM', 'MD', 'MD', 'MD', 'DDS', 'II', 'DVM', 'Jr.', 'DVM', 'MD', 'Jr.', 'DDS', 'DVM', 'DDS', 'Jr.', 'DVM', 'Jr.', 'DDS', 'MD', 'PhD', 'DDS', 'DDS', 'DVM', 'MD', 'MD', 'PhD', 'DDS', 'DDS', 'DDS', 'DDS', 'MD', 'DVM', 'DVM', 'DVM', 'DDS', 'MD', 'MD', 'MD', 'Jr.', 'PhD', 'MD', 'Jr.', 'DVM', 'DDS', 'DVM', 'MD', 'DVM', 'MD', 'DDS', 'DDS', 'PhD', 'DDS', 'Jr.', 'DDS', 'MD', 'MD', 'MD', 'MD', 'DDS', 'DVM', 'MD', 'MD', 'PhD', 'MD', 'MD', 'II', 'MD', 'Jr.', 'PhD', 'MD', 'PhD', 'MD', 'MD', 'DDS', 'Jr.', 'PhD', 'DDS', 'MD', 'DDS', 'DDS', 'MD', 'MD', 'MD', 'Jr.', 'DDS', 'DDS', 'MD', 'MD', 'MD', 'MD', 'IV', 'Jr.', 'MD', 'DDS', 'MD', 'DDS', 'MD', 'MD', 'Jr.', 'MD', 'DVM', 'DVM', 'DVM', 'MD', 'MD', 'DVM', 'DVM', 'PhD', 'Jr.', 'PhD', 'DVM', 'Jr.', 'MD', 'MD', 'DDS', 'III', 'DVM', 'DDS', 'Jr.', 'MD', 'MD', 'Jr.', 'MD', 'MD', 'DVM', 'Jr.', 'Jr.', 'DDS', 'PhD', 'DDS', 'DDS', 'DDS', 'Jr.', 'Jr.', 'MD', 'DVM', 'DDS', 'MD', 'MD', 'PhD', 'DDS', 'MD', 'DDS', 'DVM', 'DVM', 'MD', 'DDS', 'MD', 'MD', 'MD', 'Jr.', 'MD', 'DVM', 'DDS', 'MD', 'PhD', 'MD', 'II', 'Jr.', 'III', 'MD', 'PhD', 'MD', 'MD', 'PhD', 'II', 'DDS', 'DVM', 'DDS', 'MD', 'DDS', 'MD', 'DVM', 'MD', 'III', 'DDS', 'MD', 'DVM', 'MD', 'II', 'DDS', 'MD', 'MD', 'DDS', 'MD', 'MD', 'DVM', 'MD', 'MD', 'MD', 'II', 'DDS', 'Jr.', 'MD', 'DDS', 'MD', 'MD', 'MD', 'MD', 'DDS', 'IV', 'MD', 'Jr.', 'III', 'DDS', 'DDS', 'MD', 'DDS', 'DVM', 'DVM', 'PhD', 'MD', 'II', 'Li', 'DVM', 'MD', 'DVM', 'DDS', 'DDS', 'DDS', 'DVM', 'MD', 'DVM', 'MD', 'MD', 'MD', 'MD', 'Jr.', 'DVM', 'MD', 'MD', 'MD', 'MD', 'DDS', 'MD', 'PhD', 'DDS', 'MD', 'MD', 'DDS', 'Jr.', 'DDS', 'DDS', 'DVM', 'DDS', 'DDS', 'MD', 'Jr.', 'DDS', 'PhD', 'Jr.', 'DDS']\n"
     ]
    }
   ],
   "source": [
    "# Add the suffixes less than or equal to 3 to a new list.\n",
    "suffixes = []\n",
    "for name in students_to_fix:\n",
    "    if len(name.split()[-1]) <= 3:\n",
    "        suffixes.append(name.split()[-1])\n",
    "\n",
    "print(suffixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1df7bacd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Adam',\n",
       " 'Amy',\n",
       " 'Anna',\n",
       " 'Anne',\n",
       " 'Carl',\n",
       " 'Chad',\n",
       " 'Cody',\n",
       " 'Cory',\n",
       " 'Dale',\n",
       " 'Dana',\n",
       " 'Dawn',\n",
       " 'Dr.',\n",
       " 'Emma',\n",
       " 'Eric',\n",
       " 'Erik',\n",
       " 'Erin',\n",
       " 'Gail',\n",
       " 'Gary',\n",
       " 'Gina',\n",
       " 'Greg',\n",
       " 'Ian',\n",
       " 'Jill',\n",
       " 'Jodi',\n",
       " 'Joe',\n",
       " 'John',\n",
       " 'Jon',\n",
       " 'Jose',\n",
       " 'Judy',\n",
       " 'Kara',\n",
       " 'Kari',\n",
       " 'Kim',\n",
       " 'Kyle',\n",
       " 'Leah',\n",
       " 'Lisa',\n",
       " 'Lori',\n",
       " 'Luke',\n",
       " 'Lynn',\n",
       " 'Marc',\n",
       " 'Mark',\n",
       " 'Mary',\n",
       " 'Mike',\n",
       " 'Miss',\n",
       " 'Mr.',\n",
       " 'Mrs.',\n",
       " 'Ms.',\n",
       " 'Noah',\n",
       " 'Omar',\n",
       " 'Paul',\n",
       " 'Ruth',\n",
       " 'Ryan',\n",
       " 'Sara',\n",
       " 'Sean',\n",
       " 'Seth',\n",
       " 'Tara',\n",
       " 'Tina',\n",
       " 'Todd',\n",
       " 'Toni',\n",
       " 'Tony',\n",
       " 'Troy'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the unique items in the \"prefixes\" list.\n",
    "set(prefixes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd3a022",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "Not provided in the lesson, but a relatively quick way to aggregate and count the suffixes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b477ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Suffix</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MD</th>\n",
       "      <td>347.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DDS</th>\n",
       "      <td>229.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DVM</th>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jr.</th>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhD</th>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>II</th>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>III</th>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IV</th>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lee</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cox</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kim</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Li</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roy</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            N\n",
       "Suffix       \n",
       "MD      347.0\n",
       "DDS     229.0\n",
       "DVM     141.0\n",
       "Jr.     102.0\n",
       "PhD      82.0\n",
       "II       25.0\n",
       "III      15.0\n",
       "IV        7.0\n",
       "Lee       3.0\n",
       "V         2.0\n",
       "Cox       1.0\n",
       "Day       1.0\n",
       "Kim       1.0\n",
       "Li        1.0\n",
       "Roy       1.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In the lesson we used lists of dictionaries and dictionaries of lists to create Pandas dataframes.\n",
    "# We can also use zip(), which joins up two collections (e.g., lists), element-by-element\n",
    "# Here, I'm just zipping the suffixes with a big array of ones (i.e., the number 1) that is the same length as suffixes.\n",
    "\n",
    "pd.DataFrame(zip(suffixes, np.ones(len(suffixes))), \n",
    "             columns=['Suffix','N']\n",
    "            ).groupby('Suffix').agg('sum').sort_values(by='N', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da02af3",
   "metadata": {},
   "source": [
    "### 4.5.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3397002f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. Richard Scott\n",
      "Dr. Jordan Carson\n",
      "adeline Snyder MD\n",
      " Dylan Taylor MD\n",
      "Dr. Scott Gill\n",
      "iss Madison Everett\n",
      "Virginia Ramirez MD\n",
      "Joseph Morales III\n",
      "Angela Perkins DV\n",
      "Heather Allen MD\n"
     ]
    }
   ],
   "source": [
    "# Strip \"Mrs.\" from the student names\n",
    "for name in students_to_fix[:10]:\n",
    "    print(name.strip(\"Mrs.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6ad3c1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Linda Santiago'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace \"Dr.\" with an empty string.\n",
    "name = 'Dr. Linda Santiago'\n",
    "name.replace('Dr.', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a88d99",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "What isn't mentioned in the lesson is that the ```strip()```  function can be used--without arguments--to remove leading and trailing whitespace!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c76c3b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Linda Santiago'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name.replace('Dr.','').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fc8d1206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add each prefix and suffix to remove to a list.\n",
    "prefixes_suffixes = [\"Dr. \", \"Mr. \",\"Ms. \", \"Mrs. \", \"Miss \", \" MD\", \" DDS\", \" DVM\", \" PhD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4d0f6e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dusti\\anaconda3\\envs\\PythonData\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the \"prefixes_suffixes\" list and replace them with an empty space, \"\" when it appears in the student's name.\n",
    "for word in prefixes_suffixes:\n",
    "    student_data_df['student_name'] = student_data_df['student_name'].str.replace(word,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da453f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Paul Bradley',\n",
       " 'Victor Smith',\n",
       " 'Kevin Rodriguez',\n",
       " 'Richard Scott',\n",
       " 'Bonnie Ray',\n",
       " 'Bryan Miranda',\n",
       " 'Sheena Carter',\n",
       " 'Nicole Baker',\n",
       " 'Michael Roth',\n",
       " 'Matthew Greene']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put the cleaned students' names in another list.\n",
    "student_names = student_data_df[\"student_name\"].tolist()\n",
    "student_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "65b78401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new list and use it for the for loop to iterate through the list.\n",
    "students_fixed = []\n",
    "\n",
    "# Use an if statement to check the length of the name.\n",
    "\n",
    "# If the name is greater than or equal to 3, add the name to the list.\n",
    "\n",
    "for name in student_names:\n",
    "    if len(name.split()) >= 3:\n",
    "        students_fixed.append(name)\n",
    "\n",
    "# Get the length of the students' names that are greater than or equal to 3.\n",
    "len(students_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d4b053",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
